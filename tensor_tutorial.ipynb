{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"tensor_tutorial.ipynb","provenance":[],"authorship_tag":"ABX9TyMK/zEMe71tDrIHLrQ3/lAC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cIjqGhmeUdA6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":55},"outputId":"3cd45439-d2c0-4e8e-9637-bb6ff80c86ef","executionInfo":{"status":"ok","timestamp":1581511929532,"user_tz":-60,"elapsed":450,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["\"\"\"\n","What is PyTorch?\n","================\n","\n","It’s a Python-based scientific computing package targeted at two sets of\n","audiences:\n","\n","-  A replacement for NumPy to use the power of GPUs\n","-  a deep learning research platform that provides maximum flexibility\n","   and speed\n","\n","Getting Started\n","---------------\n","\n","Tensors\n","^^^^^^^\n","\n","Tensors are similar to NumPy’s ndarrays, with the addition being that\n","Tensors can also be used on a GPU to accelerate computing.\n","\"\"\""],"execution_count":41,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nWhat is PyTorch?\\n================\\n\\nIt’s a Python-based scientific computing package targeted at two sets of\\naudiences:\\n\\n-  A replacement for NumPy to use the power of GPUs\\n-  a deep learning research platform that provides maximum flexibility\\n   and speed\\n\\nGetting Started\\n---------------\\n\\nTensors\\n^^^^^^^\\n\\nTensors are similar to NumPy’s ndarrays, with the addition being that\\nTensors can also be used on a GPU to accelerate computing.\\n'"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"1KacxtkMWQSo","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","import torch"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SKieGY4eW-uR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"071cddfc-7b22-4036-d18c-1c4e151f5818","executionInfo":{"status":"ok","timestamp":1581511930218,"user_tz":-60,"elapsed":1110,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["x = torch.empty(5, 3)\n","print(x)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["tensor([[ 5.2514e-36,  0.0000e+00,  4.4842e-44],\n","        [ 0.0000e+00,         nan,  2.3416e-01],\n","        [ 6.5647e-07,  2.1953e-04,  2.6221e-09],\n","        [ 3.3211e-09,  5.3534e+22,  4.3916e-05],\n","        [ 8.3963e-07,  1.0682e-05, -3.8112e-01]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G3Ak5o0fXEPn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"d0fbc056-fe3d-4c7a-c1b0-29ac3faed1cb","executionInfo":{"status":"ok","timestamp":1581511930220,"user_tz":-60,"elapsed":1097,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["x = torch.rand(5, 3)\n","print(x)"],"execution_count":44,"outputs":[{"output_type":"stream","text":["tensor([[0.5236, 0.5546, 0.9636],\n","        [0.4088, 0.8813, 0.3651],\n","        [0.5243, 0.7486, 0.1404],\n","        [0.2872, 0.5602, 0.5238],\n","        [0.3841, 0.9576, 0.3799]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"vvg4SH1sXPLI","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"4eeaceb9-ddd8-4520-ba61-40ed7bb42f08","executionInfo":{"status":"ok","timestamp":1581511930221,"user_tz":-60,"elapsed":1081,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["x = torch.zeros(5, 3, dtype=torch.long)\n","print(x)"],"execution_count":45,"outputs":[{"output_type":"stream","text":["tensor([[0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0],\n","        [0, 0, 0]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PhZdbMkQXcCZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0cc55cca-1aa9-4d3d-fc19-245075b24b18","executionInfo":{"status":"ok","timestamp":1581511930223,"user_tz":-60,"elapsed":1066,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["#  Construct a tensor directly from data:\n","x = torch.tensor([5.5, 3])\n","print(x)"],"execution_count":46,"outputs":[{"output_type":"stream","text":["tensor([5.5000, 3.0000])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uB9IjaXYXokH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"b0966e4c-2a80-4845-c74e-c7874de1d91b","executionInfo":{"status":"ok","timestamp":1581511930224,"user_tz":-60,"elapsed":1054,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# create a tensor based on an existing tensor\n","x = x.new_ones(5, 3, dtype=torch.double)\n","print(x)"],"execution_count":47,"outputs":[{"output_type":"stream","text":["tensor([[1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.],\n","        [1., 1., 1.]], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bJcwJEZuZViW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"eff2c7b4-9398-4ca6-85cd-8a72b1b35fe3","executionInfo":{"status":"ok","timestamp":1581511930225,"user_tz":-60,"elapsed":1044,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# override the dtype\n","x = torch.randn_like(x, dtype= torch.float)\n","print(x)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["tensor([[-0.4093, -0.1106,  0.8712],\n","        [ 1.5170,  1.2946, -1.4419],\n","        [-1.9879, -0.0655, -0.4401],\n","        [ 0.5574, -0.6939, -0.2785],\n","        [-0.3420,  0.7216, -1.0032]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rhuxFi1-Zj51","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"f855cd11-c753-4e05-d5a1-8250afadbe50","executionInfo":{"status":"ok","timestamp":1581511930226,"user_tz":-60,"elapsed":1031,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["print(x.size())"],"execution_count":49,"outputs":[{"output_type":"stream","text":["torch.Size([5, 3])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nkqA7JWSaeeo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"90da88eb-31ba-4e3a-ffed-5746bc3d5cff","executionInfo":{"status":"ok","timestamp":1581511930227,"user_tz":-60,"elapsed":1018,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["y = torch.rand(5, 3)\n","print(x + y)"],"execution_count":50,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0620, -0.0838,  1.7563],\n","        [ 2.3148,  1.9011, -1.3241],\n","        [-1.5700,  0.7746,  0.0381],\n","        [ 0.9134,  0.2803,  0.1391],\n","        [ 0.2668,  0.8323, -0.6618]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Y4v1WFi6aldW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"3b10ea62-ecb8-4e23-bd8e-b64331cd1798","executionInfo":{"status":"ok","timestamp":1581511930228,"user_tz":-60,"elapsed":1008,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["print(torch.add(x, y))"],"execution_count":51,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0620, -0.0838,  1.7563],\n","        [ 2.3148,  1.9011, -1.3241],\n","        [-1.5700,  0.7746,  0.0381],\n","        [ 0.9134,  0.2803,  0.1391],\n","        [ 0.2668,  0.8323, -0.6618]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XK7hq2bZav-1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"029a8063-ac25-4f42-ff30-b867ac0b850d","executionInfo":{"status":"ok","timestamp":1581511930228,"user_tz":-60,"elapsed":990,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["result = torch.empty(5, 3)\n","torch.add(x, y, out=result)\n","print(result)  # result is the tensor"],"execution_count":52,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0620, -0.0838,  1.7563],\n","        [ 2.3148,  1.9011, -1.3241],\n","        [-1.5700,  0.7746,  0.0381],\n","        [ 0.9134,  0.2803,  0.1391],\n","        [ 0.2668,  0.8323, -0.6618]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k0s1WqQ2a-7W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"59ae44cb-d77f-40e1-8013-43199ed6319f","executionInfo":{"status":"ok","timestamp":1581511930229,"user_tz":-60,"elapsed":978,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# .. note::\n","#     Any operation that mutates a tensor in-place is post-fixed with an ``_``.\n","#     For example: ``x.copy_(y)``, ``x.t_()``, will change ``x``.\n","y.add_(x)\n","print(y)"],"execution_count":53,"outputs":[{"output_type":"stream","text":["tensor([[ 0.0620, -0.0838,  1.7563],\n","        [ 2.3148,  1.9011, -1.3241],\n","        [-1.5700,  0.7746,  0.0381],\n","        [ 0.9134,  0.2803,  0.1391],\n","        [ 0.2668,  0.8323, -0.6618]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Ckawas5FbLD2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":683},"outputId":"145f751e-24f4-448a-ad0f-7ef0d5e4f17b","executionInfo":{"status":"ok","timestamp":1581511930230,"user_tz":-60,"elapsed":967,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["help(torch.randn)"],"execution_count":54,"outputs":[{"output_type":"stream","text":["Help on built-in function randn:\n","\n","randn(...)\n","    randn(*size, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False) -> Tensor\n","    \n","    Returns a tensor filled with random numbers from a normal distribution\n","    with mean `0` and variance `1` (also called the standard normal\n","    distribution).\n","    \n","    .. math::\n","        \\text{out}_{i} \\sim \\mathcal{N}(0, 1)\n","    \n","    The shape of the tensor is defined by the variable argument :attr:`size`.\n","    \n","    Args:\n","        size (int...): a sequence of integers defining the shape of the output tensor.\n","            Can be a variable number of arguments or a collection like a list or tuple.\n","        out (Tensor, optional): the output tensor.\n","        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n","            Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n","        layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n","            Default: ``torch.strided``.\n","        device (:class:`torch.device`, optional): the desired device of returned tensor.\n","            Default: if ``None``, uses the current device for the default tensor type\n","            (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n","            for CPU tensor types and the current CUDA device for CUDA tensor types.\n","        requires_grad (bool, optional): If autograd should record operations on the\n","            returned tensor. Default: ``False``.\n","    \n","    Example::\n","    \n","        >>> torch.randn(4)\n","        tensor([-2.1436,  0.9966,  2.3426, -0.6366])\n","        >>> torch.randn(2, 3)\n","        tensor([[ 1.5954,  2.8929, -1.0923],\n","                [ 1.1719, -0.4709, -0.1996]])\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mNcLomzbb4lO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"17c23a9a-30c9-4cf0-8843-336ec9b9b790","executionInfo":{"status":"ok","timestamp":1581511930231,"user_tz":-60,"elapsed":957,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# Resizing: If you want to resize/reshape tensor, you can use ``torch.view``:\n","x = torch.randn(4, 4)\n","y = x.view(16)\n","z = x.view(-1, 8)\n","print(x.size(), y.size(), z.size())"],"execution_count":55,"outputs":[{"output_type":"stream","text":["torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q32A1UepcT4j","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"3ff0ae1f-3ba7-49f3-c3af-29dadc72d9e3","executionInfo":{"status":"ok","timestamp":1581511946541,"user_tz":-60,"elapsed":1718,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# If you have a one element tensor, use ``.item()`` to get the value as a\n","# Python number\n","x = torch.randn(1)\n","print(x)\n","print(x.item())"],"execution_count":57,"outputs":[{"output_type":"stream","text":["tensor([-0.4921])\n","-0.49213922023773193\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DxN0DY_wdSnt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":89},"outputId":"6321cd18-23da-421e-b7d0-d113e0381d6c","executionInfo":{"status":"ok","timestamp":1581512117339,"user_tz":-60,"elapsed":370,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# NumPy Bridge\n","# ------------\n","#\n","# Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n","#\n","# The Torch Tensor and NumPy array will share their underlying memory\n","# locations (if the Torch Tensor is on CPU), and changing one will change\n","# the other.\n","#\n","# Converting a Torch Tensor to a NumPy Array\n","a = torch.ones(5)\n","print(a)\n","\n","b = a.numpy()\n","print(b)\n","\n","a.add_(1)\n","print(a)\n","print(b)"],"execution_count":59,"outputs":[{"output_type":"stream","text":["tensor([1., 1., 1., 1., 1.])\n","[1. 1. 1. 1. 1.]\n","tensor([2., 2., 2., 2., 2.])\n","[2. 2. 2. 2. 2.]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wRnYXrb4d8qE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":53},"outputId":"ea0cb5a3-6a17-470c-da43-9dee75b65843","executionInfo":{"status":"ok","timestamp":1581512228351,"user_tz":-60,"elapsed":412,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# See how changing the np array changed the Torch Tensor automatically\n","import numpy as np\n","a = np.ones(5)\n","b = torch.from_numpy(a)\n","np.add(a, 1, out = a)\n","print(a)\n","print(b)"],"execution_count":61,"outputs":[{"output_type":"stream","text":["[2. 2. 2. 2. 2.]\n","tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Tcuo6QPYeXwC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"0485d5d2-5103-4efd-858e-514c7eaba64d","executionInfo":{"status":"ok","timestamp":1581512551186,"user_tz":-60,"elapsed":585,"user":{"displayName":"Hao Liu","photoUrl":"","userId":"13970451627558237465"}}},"source":["# Tensors can be moved onto any device using the ``.to`` method. Except for some chartensor\n","\n","# let us run this cell only if CUDA is available\n","# We will use ``torch.device`` objects to move tensors in and out of GPU\n","if torch.cuda.is_available():\n","  print(\"1\")\n","  device = torch.device(\"cuda\")\n","  y = torch.ones_like(x, device= device)\n","  x = x.to(device)\n","  z = x+y\n","  print(z)\n","  print(z.to(\"cpu\", torch.double))# ``.to`` can also change dtype together!"],"execution_count":63,"outputs":[{"output_type":"stream","text":["1\n","tensor([0.5079], device='cuda:0')\n","tensor([0.5079], dtype=torch.float64)\n"],"name":"stdout"}]}]}